{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcda8a60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m prices\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# load\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m prices = \u001b[43mload_all_prices\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/nachogutierrezdelaroza/Documents/2_PP/WM/Fund returns/Developed ex_UK_USA/fidelity_europe.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# --- 2. Compute returns (daily or weekly) ---\u001b[39;00m\n\u001b[32m     56\u001b[39m \n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# for daily:\u001b[39;00m\n\u001b[32m     58\u001b[39m rets = prices.pct_change().dropna()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mload_all_prices\u001b[39m\u001b[34m(pattern)\u001b[39m\n\u001b[32m     47\u001b[39m         price_frames.append(ser)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# join all on their dates\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m prices = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prices\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2_PP/WM/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2_PP/WM/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2_PP/WM/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Read & normalize all your Excel sheets into price series ----\n",
    "\n",
    "def extract_price_sheet(path, sheet_name=None):\n",
    "    \"\"\"\n",
    "    Reads one sheet of an Excel file, finds the date col + price col,\n",
    "    returns a Series indexed by date.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(path, sheet_name=sheet_name, engine='openpyxl')\n",
    "    \n",
    "    # find a column whose name contains 'date'\n",
    "    date_col = next(col for col in df.columns \n",
    "                    if re.search(r'date', col, re.IGNORECASE))\n",
    "    # find a price-like column: NAV, Close, Price, Net, etc.\n",
    "    price_col = next(col for col in df.columns \n",
    "                     if re.search(r'\\b(nav|close|price|net)\\b', col, re.IGNORECASE))\n",
    "    \n",
    "    s = df[[date_col, price_col]].dropna()\n",
    "    s = s.rename(columns={date_col: 'Date', price_col: 'Price'})\n",
    "    s['Date'] = pd.to_datetime(s['Date'])\n",
    "    s = s.set_index('Date').sort_index()\n",
    "    return s['Price']\n",
    "\n",
    "def load_all_prices(pattern=\"data/*.xlsx\"):\n",
    "    \"\"\"\n",
    "    Loads every sheet from every Excel file matching the glob pattern,\n",
    "    and returns a DataFrame of all price series side by side.\n",
    "    \"\"\"\n",
    "    price_frames = []\n",
    "    for fn in glob.glob(pattern):\n",
    "        # try default sheet plus any others\n",
    "        xls = pd.ExcelFile(fn, engine='openpyxl')\n",
    "        for sh in xls.sheet_names:\n",
    "            try:\n",
    "                ser = extract_price_sheet(fn, sheet_name=sh)\n",
    "            except StopIteration:\n",
    "                continue  # skip sheets without the right headers\n",
    "            # give it a name based on filename and sheet\n",
    "            name = f\"{fn.split('/')[-1].replace('.xlsx','')}\"\n",
    "            if len(xls.sheet_names) > 1:\n",
    "                name += f\"__{sh}\"\n",
    "            ser.name = name\n",
    "            price_frames.append(ser)\n",
    "    # join all on their dates\n",
    "    prices = pd.concat(price_frames, axis=1)\n",
    "    return prices\n",
    "\n",
    "# load\n",
    "prices = load_all_prices(\"/Users/nachogutierrezdelaroza/Documents/2_PP/WM/Fund returns/Developed ex_UK_USA/fidelity_europe.xlsx\")\n",
    "\n",
    "# --- 2. Compute returns (daily or weekly) ---\n",
    "\n",
    "# for daily:\n",
    "rets = prices.pct_change().dropna()\n",
    "\n",
    "# OR for weekly (e.g. Friday closes):\n",
    "# rets = prices.resample('W-FRI').last().pct_change().dropna()\n",
    "\n",
    "# --- 3. Annualization factors & risk-free rate ---\n",
    "trading_days = 252\n",
    "rf_annual = 0.01 # This is an example; replace with your risk-free rate\n",
    "rf_daily = (1 + rf_annual)**(1/trading_days) - 1\n",
    "\n",
    "# --- 4. Basic per-series stats ---\n",
    "mean_daily = rets.mean()\n",
    "vol_daily = rets.std()\n",
    "var_daily = rets.var()\n",
    "\n",
    "mean_ann = mean_daily * trading_days\n",
    "vol_ann = vol_daily * np.sqrt(trading_days)\n",
    "var_ann = var_daily * trading_days\n",
    "\n",
    "# --- 5. Sharpe Ratio ---\n",
    "excess = rets.sub(rf_daily)\n",
    "sharpe = excess.mean() / vol_daily * np.sqrt(trading_days)\n",
    "\n",
    "# --- 6. Sortino Ratio ---\n",
    "def sortino(r, rf=rf_daily, period=252):\n",
    "    downside = r[r < rf]\n",
    "    dd = np.sqrt((downside**2).mean()) * np.sqrt(period)\n",
    "    er = (r.mean() - rf) * period\n",
    "    return er / dd\n",
    "\n",
    "sortino = rets.apply(sortino)\n",
    "\n",
    "# --- 7. Information Ratio ---\n",
    "# pick one column as benchmark, or load a separate series\n",
    "benchmark = rets.iloc[:, 0]   # e.g. first series, or replace with your index\n",
    "active = rets.sub(benchmark, axis=0)\n",
    "ir = active.mean() / active.std() * np.sqrt(trading_days)\n",
    "\n",
    "# --- 8. Correlation & Covariance ---\n",
    "corr = rets.corr()\n",
    "cov_ann = rets.cov() * trading_days\n",
    "\n",
    "# --- 9. Summarize ---\n",
    "summary = pd.DataFrame({\n",
    "    'Mean Ann.': mean_ann,\n",
    "    'Vol. Ann.': vol_ann,\n",
    "    'Var. Ann.': var_ann,\n",
    "    'Sharpe': sharpe,\n",
    "    'Sortino': sortino,\n",
    "    'Info Ratio': ir\n",
    "}).round(4)\n",
    "\n",
    "print(\"=== Performance Summary ===\")\n",
    "print(summary)\n",
    "print(\"\\n=== Correlation Matrix ===\")\n",
    "print(corr.round(3))\n",
    "print(\"\\n=== Annualized Covariance Matrix ===\")\n",
    "print(cov_ann.round(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f3f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
