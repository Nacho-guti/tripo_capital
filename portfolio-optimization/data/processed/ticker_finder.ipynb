{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 25 excel files\n",
      "['../raw/bonds/em_bond_etf.xlsx', '../raw/bonds/jp_ult_sht_cor_bond_etf.xlsx', '../raw/bonds/ish_wld_cor_bond_etf.xlsx', '../raw/bonds/ubs_bbs_tips_bonds_etf.xlsx', '../raw/bonds/ish_glob_bond_etf.xlsx', '../raw/alternatives/gold_etf.xlsx', '../raw/alternatives/vici_reits_aim_etf.xlsx', '../raw/alternatives/aim_data_centr_etf.xlsx', '../raw/equities/min_vol/world_min_vol_etf.xlsx', '../raw/equities/min_vol/euro_min_vol_etf.xlsx', '../raw/equities/min_vol/snp_min_vol_etf.xlsx', '../raw/equities/min_vol/em_min_vol_etf.xlsx', '../raw/equities/us/spdr_world_tech.xlsx', '../raw/equities/us/amu_rai_us_etf.xlsx', '../raw/equities/em/artemis_em_etf.xlsx', '../raw/equities/other/bnp_aqua_etf.xlsx', '../raw/equities/other/gam_sus_em_etf.xlsx', '../raw/equities/other/bgf_sus_etf.xlsx', '../raw/equities/other/pic_env_etf.xlsx', '../raw/equities/uk_large_cap/uklarge_ishares_etf.xlsx', '../raw/equities/uk_large_cap/uklarge_inv_etf.xlsx', '../raw/equities/uk_large_cap/uklarge_vanguard_etf.xlsx', '../raw/equities/dev_ex_us/fid_gro_exus_etf.xlsx', '../raw/equities/dev_ex_us/ish_quality_exus_etf.xlsx', '../raw/equities/dev_ex_us/van_esg_exus_etf.xlsx']\n"
     ]
    }
   ],
   "source": [
    "def read_excel_files(folder_path, skip_folders):\n",
    "    '''\n",
    "    This function reads all excel files in a given folder and returns a list of dataframes.\n",
    "    '''\n",
    "    all_excel_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "\n",
    "        dirs[:] = [d for d in dirs if d not in skip_folders]\n",
    "\n",
    "        for file in files:    \n",
    "            if file.endswith(\".xlsx\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                all_excel_files.append(full_path)\n",
    "    return all_excel_files\n",
    "\n",
    "\n",
    "\n",
    "folder_path = \"../raw\"\n",
    "# Define subfolders to skip\n",
    "skip_folders = [\"cash\", \"risk_free\", \"benchmarks\", \"retired\"]\n",
    "\n",
    "all_excel_files = read_excel_files(folder_path, skip_folders)\n",
    "\n",
    "print(f\"Successfully read {len(all_excel_files)} excel files\")\n",
    "print(all_excel_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with empty dataframe and fill from the loop\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for i in all_excel_files:\n",
    "    \n",
    "    # Read excel file\n",
    "    df = pd.read_excel(i, index_col='Date', parse_dates=True)\n",
    "    # Get ticker value\n",
    "    ticker_value = df['Ticker'].dropna().iloc[0].strip()\n",
    "    # Rename column\n",
    "    df = df.rename(columns={'Last Price': ticker_value})\n",
    "    # Clean dataframe, this code only keeps the last price column (now ticker)\n",
    "    df_clean = df[[ticker_value]]\n",
    "    # Get three years back and change order of columns\n",
    "    three_years_back = pd.Timestamp.now() - pd.DateOffset(years=3)\n",
    "    df1 = df_clean[df_clean.index >= three_years_back]\n",
    "    df1 = df1.sort_index()\n",
    "\n",
    "    combined_df = pd.concat([combined_df, df1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 777\n",
      "Rows after: 672\n",
      "Number of dates dropped: 105\n"
     ]
    }
   ],
   "source": [
    "df_combined_nonan = combined_df.dropna()\n",
    "print(f\"Rows before: {len(combined_df)}\")\n",
    "print(f\"Rows after: {len(df_combined_nonan)}\")\n",
    "print(f\"Number of dates dropped: {len(combined_df) - len(df_combined_nonan)}\")\n",
    "\n",
    "# Save the dataframe to an excel file\n",
    "df_combined_nonan.to_excel(\"etf_combined.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker BNAMEXI LN not found\n"
     ]
    }
   ],
   "source": [
    "def create_ticker_to_file_mapping(all_excel_files):\n",
    "    ticker_map = {}\n",
    "    \n",
    "    for file_path in all_excel_files:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, index_col='Date', parse_dates=True)\n",
    "            ticker_value = df['Ticker'].dropna().iloc[0]\n",
    "            ticker_map[ticker_value] = file_path\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return ticker_map\n",
    "\n",
    "ticker_to_file_map = create_ticker_to_file_mapping(all_excel_files)\n",
    "\n",
    "def find_ticker_file(ticker):\n",
    "    file_path = ticker_to_file_map.get(ticker)\n",
    "    if file_path:\n",
    "        print(f\"Found {ticker}: {file_path}\")\n",
    "        return file_path\n",
    "    else:\n",
    "        print(f\"Ticker {ticker} not found\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "ticker_of_interest = find_ticker_file(\"BNAMEXI LN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
